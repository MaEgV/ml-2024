# All reports

### 2024.10.21
Сделано:
- Найдены относящиеся к теме работы датасеты:
    - https://huggingface.co/datasets/soufyane/DATA_SCIENCE_QA/viewer/default/train?p=10
    - https://huggingface.co/datasets/RazinAleks/SO-Python_QA-Data_Science_and_Machine_Learning_class/viewer/default/train?row=22
    - https://huggingface.co/datasets/cais/mmlu/viewer/machine_learning
    - https://huggingface.co/datasets/prsdm/Machine-Learning-QA-dataset/viewer/default/train
    - https://huggingface.co/datasets/team-bay/data-science-qa/viewer/default/train?p=3
- Выбраны метрики для оценки работы LLM/Агента/Мультиагентной сети при генерации ответов:
    - BLEU - метрика, основанная на отношении встречающихся слов и словосочетаний в результате работы модели и точного ответа к общему объему ответа. Учитывает также длину ответа;
    - ROGUE - метрика, которая, как и BLEU, основана на отношении встречающихся слов и словосочетаний разных длин в ответе модели и точном ответе к длинам как самого точного ответа, так и к результате модели;
    - BLEURT - нейросетевая метрика, которая основана на открытом наборе рейтингов, — WMT Metrics Shared Task.
    - Список может измениться ввиду недостаточности описательной способности данных метрик в различных аспектах оценивания (оценка галлюцинаций, актуальности ответов, полноты и тд)
- Оценены базовые метрики предобученной модели MistralAI, которые должны будут совершенствоваться за счет применения различных технологий улучшения работы LLM моделей (RAG, PromptTuning, разработка путей и средств валидации модели, возможно дообучение LoRA открытой модели, при нахождении датасетов должного объема):
    - Средние значения метрик оценены по 100 записям из 11к ввиду долгого расчета и большого ответа моделей
    - ROGUE-1 = 0.13, ROGUE-2 = 0.06, ROGUE-L = 0.10
    - BLEU = 0.017
    - BLEURT = -0.312

### 2024.10.07
Сделано:
- Заполнено readme.md проекта.
