{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Журнал оценки сети на реальных данных\n",
    "\n",
    "Данный журнал предназначен для валидирования результата обучения сети на синтетических изображениях, а также для визуализации работы на реальных данных.\n",
    "Предлагается следующий сценарий валидирования:\n",
    "1. Валидирование на синтетических сферах и палочках:\n",
    "    - Метрики: MSE, PSNE, время.\n",
    "    - Визуальный анализ: поточечная карта отклонений, сравение результатов нескольких методов, построение графиков lineplot.\n",
    "2. Анализ шумоподавления на синтетических данных:\n",
    "    - Анализ результата работы с пуассновским шумом с параметром лямбда 0, 1, 3, 5 на тех же изображениях.\n",
    "    - Сравнение результата с такими же показателями с ричардсоном-люси.\n",
    "3. Визуализация работы методов на реальных данных:\n",
    "    - 2 изображения нейронов, 2 изображения активновых тяжей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Блок констант и входных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T15:27:04.196251Z",
     "iopub.status.busy": "2024-11-30T15:27:04.194491Z",
     "iopub.status.idle": "2024-11-30T15:27:04.228788Z",
     "shell.execute_reply": "2024-11-30T15:27:04.225421Z",
     "shell.execute_reply.started": "2024-11-30T15:27:04.196189Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = \"/gpu:0\"\n",
    "\n",
    "# \"path\" - path to image, \"color\": idx of color channel (None for black and white, 0 - for red, 1 - for green, 2 - for blue)\n",
    "#X_SCALE, Y_SCALE, Z_SCALE = 0.019, 0.019, 0.2\n",
    "X_SCALE, Y_SCALE, Z_SCALE = 0.022, 0.022, 0.1\n",
    "\n",
    "# Chunk params\n",
    "CHUNK_SIZE = 128\n",
    "OFFSET_SIZE = 64\n",
    "\n",
    "REAL_IMAGES = [\n",
    "    {\n",
    "        \"path\": \"./data/validation/real/astrocyte_dgtu\",\n",
    "        \n",
    "        \"source_img_name\":\"astrocyte_dgtu.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_neuron.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-10-24_17-37/best_model.h5\",      # <---- dgtu data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T20:05:59.468642Z",
     "iopub.status.busy": "2024-11-28T20:05:59.467741Z",
     "iopub.status.idle": "2024-11-28T20:05:59.489991Z",
     "shell.execute_reply": "2024-11-28T20:05:59.489049Z",
     "shell.execute_reply.started": "2024-11-28T20:05:59.468599Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "REAL_IMAGES = [\n",
    "    {\n",
    "        \"path\": \"./data/validation/real/cut1\",\n",
    "        \n",
    "        \"source_img_name\":\"mono_cut1.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_cut1.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-11-28_12-37/best_model.h5\",      # <---- cuts data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"./data/validation/real/cut2\",\n",
    "        \n",
    "        \"source_img_name\":\"mono_cut2.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_cut2.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-11-28_12-37/best_model.h5\",      # <---- cuts data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"./data/validation/real/cut3\",\n",
    "        \n",
    "        \"source_img_name\":\"mono_cut3.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_cut3.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-11-28_12-37/best_model.h5\",      # <---- cuts data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"./data/validation/real/cut4\",\n",
    "        \n",
    "        \"source_img_name\":\"mono_cut4.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_cut4.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-11-28_12-37/best_model.h5\",      # <---- cuts data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"./data/validation/real/cut5\",\n",
    "        \n",
    "        \"source_img_name\":\"mono_cut5.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_cut5.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-11-28_12-37/best_model.h5\",      # <---- cuts data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"./data/validation/real/cut6\",\n",
    "        \n",
    "        \"source_img_name\":\"mono_cut6.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_cut6.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-11-28_12-37/best_model.h5\",      # <---- cuts data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T12:02:48.451087Z",
     "iopub.status.busy": "2024-11-28T12:02:48.450128Z",
     "iopub.status.idle": "2024-11-28T12:02:48.469874Z",
     "shell.execute_reply": "2024-11-28T12:02:48.469059Z",
     "shell.execute_reply.started": "2024-11-28T12:02:48.451028Z"
    }
   },
   "outputs": [],
   "source": [
    "REAL_IMAGES = [\n",
    "    {\n",
    "        \"path\": \"./data/validation/real/cut1\",\n",
    "        \n",
    "        \"source_img_name\":\"mono_raw_cut1.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_raw_cut1.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-11-28_12-37/best_model.h5\",      # <---- cuts data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"./data/validation/real/cut2\",\n",
    "        \n",
    "        \"source_img_name\":\"mono_raw_cut2.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_raw_cut2.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-11-28_12-37/best_model.h5\",      # <---- cuts data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"./data/validation/real/cut3\",\n",
    "        \n",
    "        \"source_img_name\":\"mono_raw_cut3.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_raw_cut3.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-11-28_12-37/best_model.h5\",      # <---- cuts data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"./data/validation/real/cut4\",\n",
    "        \n",
    "        \"source_img_name\":\"mono_raw_cut4.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_raw_cut4.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-11-28_12-37/best_model.h5\",      # <---- cuts data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"./data/validation/real/cut5\",\n",
    "        \n",
    "        \"source_img_name\":\"mono_raw_cut5.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_raw_cut5.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-11-28_12-37/best_model.h5\",      # <---- cuts data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"./data/validation/real/cut6\",\n",
    "        \n",
    "        \"source_img_name\":\"mono_raw_cut6.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_raw_cut6.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-11-28_12-37/best_model.h5\",      # <---- cuts data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T12:02:48.472758Z",
     "iopub.status.busy": "2024-11-28T12:02:48.471749Z",
     "iopub.status.idle": "2024-11-28T12:02:48.495274Z",
     "shell.execute_reply": "2024-11-28T12:02:48.494193Z",
     "shell.execute_reply.started": "2024-11-28T12:02:48.472714Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "REAL_IMAGES = [\n",
    "    \n",
    "    {\n",
    "        \"path\": \"./data/validation/real/conus4\",\n",
    "        \n",
    "        \"source_img_name\":\"mono_conus4.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_conus4.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-11-25_21-46/best_model.h5\",      # <---- conus data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"./data/validation/real/conus1\",\n",
    "        \n",
    "        \"source_img_name\":\"mono_conus1.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_conus1.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-11-25_21-46/best_model.h5\",      # <---- conus data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"./data/validation/real/conus2\",\n",
    "        \n",
    "        \"source_img_name\":\"mono_conus2.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_conus2.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-11-25_21-46/best_model.h5\",      # <---- conus data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"./data/validation/real/conus3\",\n",
    "        \n",
    "        \"source_img_name\":\"mono_conus3.tif\", \n",
    "        \"color\" : None,\n",
    "        \"deconv_res_path\" : \"ru_decon_conus3.tiff\",\n",
    "        \n",
    "        \"metrics\" : \"metrics.json\",\n",
    "        \"blured_vis_path\" : \"blured_vis.png\",\n",
    "        \"res_vis_path\" : \"ru_decon_vis.png\",\n",
    "        \"weights\" : \"./train_logs/2024-11-25_21-46/best_model.h5\",      # <---- conus data weights\n",
    "        \"dataset_path\" : \"./../DataGeneration/red_data_dgtu\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Блок импортов, функций и дополнительных инициализаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T15:27:11.773595Z",
     "iopub.status.busy": "2024-11-30T15:27:11.771926Z",
     "iopub.status.idle": "2024-11-30T15:27:15.318869Z",
     "shell.execute_reply": "2024-11-30T15:27:15.317626Z",
     "shell.execute_reply.started": "2024-11-30T15:27:11.773551Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import typing as tp\n",
    "import math as m\n",
    "import time\n",
    "import json\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from plotting_utils import *\n",
    "from image_processing import *\n",
    "from utils import *\n",
    "from big_image_manager import BigImageManager\n",
    "#from CNNModels.cnn_deconv_unet import CNNDeconvUNet\n",
    "from CNNModels.cnn_deconv_unet_exp import CNNDeconvUNet\n",
    "from CNNModels.cnn_deconv_rescoder import CNNDeconvRescoder\n",
    "\n",
    "def generate_synthetic_pair(img : np.ndarray, blured_sphere : np.ndarray, accurate_sphere : np.ndarray) -> tp.Tuple[np.ndarray]:\n",
    "    blured_sphere = blured_sphere.astype(\"float32\") / np.sum(blured_sphere)\n",
    "    accurate_sphere = accurate_sphere.astype(\"float32\") / np.sum(accurate_sphere)\n",
    "    \n",
    "    x_data = convolution(img, blured_sphere)\n",
    "    y_data = convolution(img, accurate_sphere)\n",
    "        \n",
    "    return x_data, y_data\n",
    "\n",
    "def deconvolve(img : np.ndarray, model_path : str) -> np.ndarray:\n",
    "    # make chunks\n",
    "    chunk_manager = BigImageManager(img, CHUNK_SIZE, OFFSET_SIZE, img.shape[0])\n",
    "    chunks = chunk_manager.split_in_chunks()\n",
    "    chunk_shape = chunks[0].shape\n",
    "\n",
    "    # Init model\n",
    "    model = CNNDeconvUNet.build_model((*chunk_shape, 1))\n",
    "    #model = CNNDeconvRescoder.build_model((*chunk_shape, 1))\n",
    "    model.load_weights(model_path)\n",
    "\n",
    "    # init tensors in one call to more effecienty\n",
    "    chunks_list = [chunk.get_data().reshape(1, *chunk_shape, 1) for chunk in chunks]\n",
    "    datasTensor = tf.convert_to_tensor(np.asarray(chunks_list), tf.float32)\n",
    "    \n",
    "    # prediction\n",
    "    results = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        data_to_predict = model(datasTensor[i]).numpy().reshape(*chunk_shape)\n",
    "        chunk.set_chunk_data(data_to_predict)\n",
    "        results.append(chunk)\n",
    "    \n",
    "    # Init back to save\n",
    "    result = chunk_manager.concatenate_chunks_into_image(results)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Блок валидирования на синтетических данных\n",
    "### 0. Подгрузка сфер из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T15:27:15.322105Z",
     "iopub.status.busy": "2024-11-30T15:27:15.320839Z",
     "iopub.status.idle": "2024-11-30T15:27:15.728987Z",
     "shell.execute_reply": "2024-11-30T15:27:15.727314Z",
     "shell.execute_reply.started": "2024-11-30T15:27:15.322056Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for image in REAL_IMAGES:\n",
    "    blured_bead = np.load(os.path.join(image[\"dataset_path\"], \"blured_bead.npy\"))\n",
    "    clear_bead = np.load(os.path.join(image[\"dataset_path\"], \"clear_bead.npy\"))\n",
    "\n",
    "    #psf = load_colorfull_tiff(\"./data/validation/synthetic/psf.tiff\", None)\n",
    "\n",
    "    print(np.array(blured_bead.shape) // 2, blured_bead[15, 31, 31])\n",
    "    print(np.unravel_index(clear_bead.argmax(), clear_bead.shape), clear_bead[np.unravel_index(clear_bead.argmax(), clear_bead.shape)])\n",
    "    print(np.unravel_index(blured_bead.argmax(), blured_bead.shape), blured_bead[np.unravel_index(blured_bead.argmax(), blured_bead.shape)])\n",
    "    #print(np.unravel_index(psf.argmax(), psf.shape), psf[np.unravel_index(psf.argmax(), psf.shape)])\n",
    "\n",
    "    plot_image_slices((clear_bead * (255.0 / np.amax(clear_bead))).astype(\"uint8\"), cm.jet, X_SCALE, Z_SCALE, np.array(clear_bead.shape) // 2)\n",
    "    plot_image_slices((blured_bead * (255.0 / np.amax(blured_bead))).astype(\"uint8\"), cm.jet, X_SCALE, Z_SCALE, np.array(blured_bead.shape) // 2)        \n",
    "    \n",
    "    save_tiff((clear_bead / np.amax(clear_bead) * 255).astype(\"uint8\"), os.path.join(image['path'],  \"clear_bead.tiff\"), None)\n",
    "    save_tiff((blured_bead / np.amax(blured_bead) * 255).astype(\"uint8\"), os.path.join(image['path'], \"blured_bead.tiff\"), None)\n",
    "    \n",
    "    #save_image_slices(psf, \"./data/validation/synthetic/psf_vis.png\", cm.jet, X_SCALE, Z_SCALE, np.array(psf.shape) // 2)        \n",
    "    #save_image_slices(psf, \"./data/validation/rl_results/psf_vis.png\", cm.jet, X_SCALE, Z_SCALE, np.array(psf.shape) // 2)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Проверка на реальных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T15:27:16.580023Z",
     "iopub.status.busy": "2024-11-30T15:27:16.578194Z",
     "iopub.status.idle": "2024-11-30T15:27:16.618619Z",
     "shell.execute_reply": "2024-11-30T15:27:16.617400Z",
     "shell.execute_reply.started": "2024-11-30T15:27:16.579964Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PADDING_SIZE_FROM_EACH_SIZE = 15\n",
    "\n",
    "def shading_preproc(img):\n",
    "    new_img = np.pad(img, ((PADDING_SIZE_FROM_EACH_SIZE, PADDING_SIZE_FROM_EACH_SIZE), (0, 0), (0, 0)), mode=\"edge\")\n",
    "    \n",
    "    for i in range(PADDING_SIZE_FROM_EACH_SIZE):\n",
    "        new_img[i] = new_img[i] * (i / PADDING_SIZE_FROM_EACH_SIZE)\n",
    "        new_img[-(i + 1)] = new_img[-(i + 1)] * (i / PADDING_SIZE_FROM_EACH_SIZE)\n",
    "    return new_img\n",
    "\n",
    "preprocessing_dict = [\n",
    "    {\"name\":\"no_preproc_\", \"preproc\" : (lambda img : img)},\n",
    "    #{\"name\":\"shading_preproc_\", \"preproc\" : (lambda img : shading_preproc(img))},\n",
    "    #{\"name\":\"zero_padding_\", \"preproc\" : (lambda img : np.pad(img, ((PADDING_SIZE_FROM_EACH_SIZE, PADDING_SIZE_FROM_EACH_SIZE), (0, 0), (0, 0)), mode=\"constant\", constant_values=0))},\n",
    "    #{\"name\":\"same_padding_\", \"preproc\" : (lambda img : np.pad(img, ((PADDING_SIZE_FROM_EACH_SIZE, PADDING_SIZE_FROM_EACH_SIZE), (0, 0), (0, 0)), mode=\"edge\"))}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T15:27:16.926907Z",
     "iopub.status.busy": "2024-11-30T15:27:16.925456Z",
     "iopub.status.idle": "2024-11-30T16:17:41.520402Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy import ndimage\n",
    "\n",
    "for img_info in REAL_IMAGES:\n",
    "    print(os.path.join(img_info['path'], img_info['source_img_name']))\n",
    "    org_img = load_colorfull_tiff(os.path.join(img_info['path'], img_info['source_img_name']), img_info['color'])\n",
    "    \n",
    "    print(stats.mode(org_img, axis = None), np.median(org_img), np.mean(org_img))\n",
    "    org_img[org_img <= np.median(org_img) * 1.5] = np.median(org_img)* 1.5\n",
    "    org_img = org_img - np.median(org_img)* 1.5\n",
    "    \n",
    "    #org_img = gaus_blurring(org_img, 2.5)\n",
    "    multiplyer = 0.5 / np.amax(org_img)\n",
    "    org_img = org_img.astype(\"float32\") * multiplyer\n",
    "    \n",
    "    #org_img = ndimage.median_filter(org_img, size=(3, 10, 10))\n",
    "    #org_img = ndimage.gaussian_filter(org_img, sigma=(1, 2.5, 2.5))\n",
    "    \n",
    "    #org_img = np.rot90(org_img, 2, (1, 2))\n",
    "        \n",
    "    for preproc in preprocessing_dict:\n",
    "        img = preproc[\"preproc\"](org_img)    \n",
    "        #plot_image_slices(img, cm.jet, X_SCALE, Z_SCALE, np.array(img.shape) // 2)\n",
    "        \n",
    "        # start deconv and count metrics\n",
    "        t = time.process_time()\n",
    "        img_info[\"weights\"] = \"./train_logs/2024-11-04_01-37/best_model.h5\"\n",
    "        with tf.device(DEVICE):\n",
    "            deconv_res = deconvolve(img, img_info[\"weights\"])\n",
    "        elapsed_time = time.process_time() - t\n",
    "        print(elapsed_time)\n",
    "\n",
    "        deconv_res = np.clip(deconv_res, 0, np.amax(deconv_res)) # for avoiding high intensivities accuring by edge effect\n",
    "        deconv_res = ndimage.gaussian_filter(deconv_res, sigma=(1.5, 3, 3))\n",
    "        deconv_res = ndimage.median_filter(deconv_res, size=(2, 9, 9))\n",
    "        \n",
    "        #plot_image_slices(deconv_res, cm.jet, X_SCALE, Z_SCALE, np.array(deconv_res.shape) // 2)\n",
    "    \n",
    "        save_image_slices(img, os.path.join(img_info['path'], preproc[\"name\"] + img_info[\"blured_vis_path\"]), cm.jet, X_SCALE, Z_SCALE, np.array(deconv_res.shape) // 2)\n",
    "        save_image_slices(deconv_res, os.path.join(img_info['path'], preproc[\"name\"] + img_info[\"res_vis_path\"]), cm.jet, X_SCALE, Z_SCALE, np.array(deconv_res.shape) // 2)\n",
    "    \n",
    "        # save tiff representation of generated data\n",
    "        save_tiff((deconv_res / np.amax(deconv_res) * 255).astype(\"uint8\"), os.path.join(img_info['path'], preproc[\"name\"] + img_info[\"deconv_res_path\"]), img_info['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
