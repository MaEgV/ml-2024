# Class which provides data reading, generated by 'DatasetGenerator' from '../DataGeneration/dataset_generator.py'
import os
import numpy as np
import json
import h5py
import typing as tp
from random import shuffle

class DatasetReader():
    # Constants for inner logic
    DATA_LENGTH_FIELD = "size"          # For size field in *.hdf5 file
    DATA_SHAPE_FIELD = "data_shape"     # For shape field in *.hdf5 file
    X_DATA_PREFIX = "X_"                # For input data in *.hdf5 file
    Y_DATA_PREFIX = "Y_"                # For true data in *.hdf5 file
    HDF5_FORMAT = ".hdf5"
    INFO_FILE_NAME = "info.json"

    # Constants for json data
    DATA_NAME_FIELD = "name"
    DATA_DESCRIPTION_FILED = "description"
    
    def __init__(self, 
                dataset_folder_path : str):

        # Check correct of dataset
        if os.path.isdir(dataset_folder_path) == False:
            raise Exception(f"DatasetReader error: there is no folder with '{dataset_folder_path}' path!")
        
        dataset_format_files = [file for file in os.listdir(dataset_folder_path) if file.endswith(self.HDF5_FORMAT)]
        if len(dataset_format_files) != 1:
            raise Exception(f"DatasetReader error: there is {len(dataset_format_files)} files with '{self.HDF5_FORMAT}' extention, but expected one!")
        else:
            self.__dataset_path = os.path.join(dataset_folder_path, dataset_format_files[0])

        if os.path.exists(os.path.join(dataset_folder_path, self.INFO_FILE_NAME)) == False:
            raise Exception(f"DatasetReader error: there is no {self.INFO_FILE_NAME} in {dataset_folder_path}!")
    
        # Load info about dataset
        with open(os.path.join(dataset_folder_path, self.INFO_FILE_NAME), 'r') as jf:
            self.__dataset_info = json.load(jf)
        pass


    # TODO : Make func useful and for unsupervised learning
    def read_all_data(self, need_shuffle : bool = False) -> tp.Tuple[np.ndarray]:
        with h5py.File(self.__dataset_path, 'r') as f:
            power = self.__dataset_info[self.DATA_LENGTH_FIELD]
            total_data_shape = [power, *self.__dataset_info[self.DATA_SHAPE_FIELD], 1]
            X_data, Y_data = np.zeros(total_data_shape), np.zeros(total_data_shape)

            indxs = list(range(power))
            if need_shuffle:
                shuffle(indxs)
            
            for i in range(power):
                X_data[i, ...] = f[self.X_DATA_PREFIX + str(indxs[i])][:][...]
                Y_data[i, ...] = f[self.Y_DATA_PREFIX + str(indxs[i])][:][...]
                        
            return X_data, Y_data

    @staticmethod
    def __get_splited_indexes(total_elements : int, train_val_coef : float) -> tp.Tuple[tp.List]:
        # total count of each list
        train_elements = int(total_elements * train_val_coef)
        val_elements = total_elements - train_elements

        # make randomize indexes
        list1 = [True] * train_elements
        list2 = [False] * val_elements
        listcomb = list1 + list2
        listcomb = np.random.choice(listcomb, total_elements, replace=False)
        train_indices = np.argwhere(listcomb == True)
        valid_indices = np.argwhere(listcomb == False)

        return train_indices, valid_indices

    # TODO : Make func useful and for unsupervised learning
    def read_and_split_all_data(self, train_val_coef : float = 0.8, need_shuffle : bool = False):
        with h5py.File(self.__dataset_path, 'r') as f:
            power = self.__dataset_info[self.DATA_LENGTH_FIELD]
            train_indices, valid_indices = DatasetReader.__get_splited_indexes(power, train_val_coef) 
            
            if need_shuffle:
                np.random.shuffle(train_indices)
                np.random.shuffle(valid_indices)

            train_data_shape = [len(train_indices), *self.__dataset_info[self.DATA_SHAPE_FIELD], 1]
            val_data_shape = [len(valid_indices), *self.__dataset_info[self.DATA_SHAPE_FIELD], 1]
            
            X_train, Y_train = np.zeros(train_data_shape), np.zeros(train_data_shape)
            X_val, Y_val = np.zeros(val_data_shape), np.zeros(val_data_shape)

            for i in range(len(train_indices)):
                X_train[i, ..., 0] = f[self.X_DATA_PREFIX + str(train_indices[i][0])][:][...]
                Y_train[i, ..., 0] = f[self.Y_DATA_PREFIX + str(train_indices[i][0])][:][...]

            for i in range(len(valid_indices)):
                X_val[i, ..., 0] = f[self.X_DATA_PREFIX + str(valid_indices[i][0])][:][...]
                Y_val[i, ..., 0] = f[self.Y_DATA_PREFIX + str(valid_indices[i][0])][:][...]
            
            return X_train, Y_train, X_val, Y_val

    @property
    def shape(self):
        return self.__dataset_info[self.DATA_SHAPE_FIELD]
