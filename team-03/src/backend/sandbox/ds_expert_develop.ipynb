{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Журнал разработки и тестирования агента/мультиагента, специализирующего в DataScience + MachineLearning + DeepLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, get_dataset_split_names\n",
    "\n",
    "datasets_loads = [\n",
    "    # {\n",
    "    #     \"NAME\": \"soufyane/DATA_SCIENCE_QA\",\n",
    "    #     \"Q\": \"Question\",\n",
    "    #     \"A\": \"Answer\"\n",
    "    # },\n",
    "    {\n",
    "        \"NAME\": \"team-bay/data-science-qa\",\n",
    "        \"Q\": \"question\",\n",
    "        \"A\": \"answer\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'adore programmer.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "from dotenv import load_dotenv\n",
    "import evaluate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatMistralAI(\n",
    "    model=\"mistral-small-latest\",\n",
    "    temperature=0,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "true_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'team-bay/data-science-qa', split 'train', row 1/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 2/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 3/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 4/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 5/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 6/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 7/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 8/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 9/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 10/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 11/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 12/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 13/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 14/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 15/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 16/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 17/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 18/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 19/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 20/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 21/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 22/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 23/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 24/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 25/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 26/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 27/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 28/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 29/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 30/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 31/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 32/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 33/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 34/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 35/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 36/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 37/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 38/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 39/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 40/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 41/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 42/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 43/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 44/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 45/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 46/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 47/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 48/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 49/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 50/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 51/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 52/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 53/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 54/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 55/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 56/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 57/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 58/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 59/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 60/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 61/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 62/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 63/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 64/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 65/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 66/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 67/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 68/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 69/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 70/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 71/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 72/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 73/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 74/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 75/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 76/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 77/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 78/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 79/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 80/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 81/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 82/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 83/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 84/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 85/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 86/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 87/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 88/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 89/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 90/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 91/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 92/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 93/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 94/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 95/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 96/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 97/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 98/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 99/473.\n",
      "Dataset 'team-bay/data-science-qa', split 'train', row 100/473.\n"
     ]
    }
   ],
   "source": [
    "for ds_load in datasets_loads:\n",
    "    splits = get_dataset_split_names(ds_load[\"NAME\"])\n",
    "    for split in splits:\n",
    "        ds_split = load_dataset(ds_load[\"NAME\"], split=split)\n",
    "        \n",
    "        for i in range(100):\n",
    "            print(f\"Dataset '{ds_load['NAME']}', split '{split}', row {i+1}/{ds_split.num_rows}.\")\n",
    "            messages = [\n",
    "               (\n",
    "                    \"system\",\n",
    "                    \"You are a helpful assistant that answers on questions, which are related to data science or machine learning.\",\n",
    "                ),\n",
    "                (\"human\", ds_split[ds_load[\"Q\"]][i]),\n",
    "            ]\n",
    "            ai_msg = llm.invoke(messages)\n",
    "            predictions.append(ai_msg.content)\n",
    "            true_answers.append(ds_split[ds_load[\"A\"]][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.01793607127263799,\n",
       " 'precisions': [0.05018583501173148,\n",
       "  0.023803083581282122,\n",
       "  0.012489314234482183,\n",
       "  0.006936754351141848],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 16.11274673803948,\n",
       " 'translation_length': 48161,\n",
       " 'reference_length': 2989}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "results = bleu.compute(predictions=predictions, references=true_answers)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.13003004792455541,\n",
       " 'rouge2': 0.06808846128378661,\n",
       " 'rougeL': 0.10825821395233363,\n",
       " 'rougeLsum': 0.11872244724027176}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "results = rouge.compute(predictions=predictions, references=true_answers)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:evaluate_modules.metrics.evaluate-metric--bleurt.98e148b2f8c4a88aba5037e4e0e90c9fd9ec35dc37a054ded8cfef0fa801ffab.bleurt:Using default BLEURT-Base checkpoint for sequence maximum length 128. You can use a bigger model for better results with e.g.: evaluate.load('bleurt', 'bleurt-large-512').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scores': [-0.44078388810157776, -0.13905742764472961, -0.1375528872013092, -0.6471426486968994, -0.0185844786465168, -0.24806255102157593, -0.20272958278656006, -0.43642058968544006, -0.1816762387752533, -0.38655850291252136, -0.44491833448410034, -0.6149903535842896, -0.37793418765068054, -0.8058252930641174, -0.5447061061859131, -0.4497118890285492, -0.01762155070900917, -0.6250327229499817, -0.1843060553073883, -0.32236918807029724, -0.20398402214050293, -0.1957666575908661, -0.018202949315309525, -0.3393728733062744, -0.43493419885635376, -0.11338627338409424, -0.12296149134635925, -0.15445387363433838, -0.32360365986824036, -0.815139889717102, -0.19238919019699097, -0.3668462336063385, -0.41167300939559937, -0.5887979865074158, 0.14859294891357422, -0.2813679873943329, -0.37445324659347534, -0.46711575984954834, -0.3773594796657562, -0.1781224012374878, -0.5071555972099304, 0.010943692177534103, -0.0038436688482761383, -0.4347352981567383, -0.2485138475894928, -0.4124450385570526, 0.03207265958189964, -0.058640215545892715, -0.014330361038446426, -0.10099300742149353, -0.25294533371925354, -0.28302717208862305, -0.3564642369747162, -0.13560011982917786, -0.6768081784248352, 0.06847280263900757, -0.07841905951499939, -0.3370296061038971, -0.30945998430252075, -0.2098959982395172, -0.3137907385826111, -0.31731322407722473, -0.19093865156173706, -0.19497185945510864, -0.3690110743045807, -0.3181381821632385, -0.4768194556236267, -0.2886708378791809, -0.3542204797267914, 0.02093621715903282, -0.4861123561859131, -0.579253077507019, -0.18091937899589539, -0.14001581072807312, -0.7267095446586609, -0.6871653199195862, 0.04010849818587303, -0.599035918712616, -0.6459950804710388, -0.694818913936615, -0.12129613757133484, -0.3526201546192169, -0.487403929233551, -0.47111350297927856, -0.21862003207206726, -0.21971631050109863, -0.08183541893959045, -0.580682635307312, -0.28072479367256165, -0.10788765549659729, -0.4174053370952606, -0.5162269473075867, -0.4321097433567047, -0.09789901971817017, -0.47210928797721863, -0.7854829430580139, -0.1549481749534607, -0.14569589495658875, -0.1446957290172577, -0.3244948089122772]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bleurt = evaluate.load(\"bleurt\", module_type=\"metric\", checkpoint=\"bleurt-large-512\")\n",
    "results = bleurt.compute(predictions=predictions, references=true_answers)\n",
    "\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 -0.31261963926255704 0.21429681531101655\n"
     ]
    }
   ],
   "source": [
    "print(len(results[\"scores\"]), np.mean(results[\"scores\"]), np.std(results[\"scores\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
